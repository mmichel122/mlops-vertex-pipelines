# ğŸš€ Vertex AI MLOps Pipeline

**Training â†’ Evaluation â†’ Conditional Deployment â†’ Model Registry â†’ GitHub Actions**

This repository implements a **production-grade MLOps pipeline** on **Google Cloud Vertex AI**, including:

* Automated model training
* Evaluation and metrics logging
* Conditional deployment (only if accuracy improves)
* Model versioning in Vertex AI Model Registry
* Containerized training jobs
* Pipeline execution via GitHub Actions
* Artifact storage in GCS

---

## ğŸ“ Repository Structure

```
vertex-pipelines/
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â””â”€â”€ deploy.py
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ eval.py
â”‚
â””â”€â”€ .github/workflows/
    â””â”€â”€ vertex_pipeline.yaml
```

---

## ğŸ§± Components Overview

| Component                               | Purpose                                                    |
| --------------------------------------- | ---------------------------------------------------------- |
| `preprocess.py`                         | Loads and prepares dataset (GCS or local)                  |
| `train.py`                              | Launches a Vertex Custom Training Job using your container |
| `evaluate.py`                           | Computes accuracy + confusion matrix                       |
| `deploy.py`                             | Deploys model to a Vertex AI Endpoint                      |
| `compare_accuracy` (inside pipeline.py) | Decides whether new model should be deployed               |

---

## ğŸš€ How the Pipeline Works

### **1. Preprocess**

Loads dataset (GCS or fallback Iris dataset) and stores a cleaned artifact.

### **2. Train**

Runs your training code inside a custom container:

```
europe-west4-docker.pkg.dev/<PROJECT>/mlops/train:latest
```

Outputs a trained model:

```
model.pkl
```

### **3. Evaluate**

Generates evaluation artifacts:

* `metrics.json`
* `confusion_matrix.png`

### **4. Compare Accuracy**

Deployment occurs **only if:**

```
new_accuracy > baseline_accuracy
```

### **5. Register Model**

Uploads the new model to **Vertex AI Model Registry**.

### **6. Deploy**

Deploys to an existing Vertex endpoint:

```
iris-classification-endpoint
```

Traffic is switched 100% to the new model.

---

## âš™ï¸ Build & Push Training Container

```bash
cd training/docker

gcloud builds submit --tag \
  europe-west4-docker.pkg.dev/<PROJECT>/mlops/train:latest
```

---

## ğŸ” Triggering via GitHub Actions

When pushing to `main`, the workflow will:

1. Build & push training Docker image
2. Compile the Vertex AI Pipeline
3. Submit a pipeline job
4. Display pipeline run ID in the logs

Required secret:

```
GCP_SA_KEY
```

---

## â–¶ï¸ Running Pipeline Manually

```bash
python3 -m venv venv
source venv/bin/activate
pip install kfp google-cloud-aiplatform pyyaml

python pipeline/pipeline.py

gcloud ai pipelines run \
  --project=<PROJECT> \
  --region=europe-west4 \
  --pipeline-name=vertex-mlops \
  --file=pipeline.json
```

---

## ğŸ“¦ Outputs

Artifacts stored in:

```
gs://mlops-vertex-playground/pipelines/<run-id>/
```

Models stored in Vertex AI:

```
Models â†’ iris-model â†’ Versions
```

---

## ğŸ§  Notes

* Designed for enterprise-grade MLOps learning.
* Mirrors real-world Google Cloud ML Architect best practices.
* Code follows modular, testable, and extensible architecture.

---

## ğŸ¤ Need More?

I can add:

* Terraform infrastructure
* Monitoring dashboards (Vertex AI Monitoring)
* CI/CD for container image build + pipeline run
* Canary deployments / blue-green
* Multi-model A/B testing

Just ask: **â€œadd monitoringâ€**, **â€œadd terraform infraâ€**, or **â€œadd CI/CD image buildâ€**.
